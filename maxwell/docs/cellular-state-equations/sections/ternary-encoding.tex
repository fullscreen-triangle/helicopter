\section{Ternary Encoding of S-Entropy Space}
\label{sec:ternary}

\subsection{Representation Theorem}

Binary encoding naturally represents one-dimensional information through the $2^k$ hierarchy. Three-dimensional S-entropy space requires ternary encoding.

\begin{theorem}[Trit-Coordinate Correspondence]
\label{thm:trit_coordinate}
Each $k$-trit ternary string $(t_1,t_2,\ldots,t_k)$ with $t_i \in \{0,1,2\}$ maps bijectively to a cell in the $3^k$ partition of S-entropy space $\Sspace = [0,1]^3$.
\end{theorem}

\begin{proof}
Define refinement operations:
\begin{align}
R_0: [0,1]^3 &\to [0,1]^3 \quad \text{(refine along } \Sk \text{)} \\
R_1: [0,1]^3 &\to [0,1]^3 \quad \text{(refine along } \St \text{)} \\
R_2: [0,1]^3 &\to [0,1]^3 \quad \text{(refine along } \Se \text{)}
\end{align}
Each operation partitions one dimension into three equal intervals. A $k$-trit string $(t_1,\ldots,t_k)$ specifies the sequence $R_{t_1} \circ R_{t_2} \circ \cdots \circ R_{t_k}$, producing a unique cell in the $3^k$ partition. Distinct trit strings yield distinct cells by construction. Every cell corresponds to exactly one refinement sequence, establishing bijection.
\end{proof}

\begin{corollary}[Cell Volume]
The volume of the cell corresponding to $k$-trit string $(t_1,\ldots,t_k)$ is $3^{-k}$.
\end{corollary}

\subsection{Molecular Coordinate Transformation}

The ternary encoding extends naturally to molecular data through S-entropy coordinate transformation~\cite{weininger1988smiles,cover2006elements}.

\begin{definition}[Genomic Coordinate Mapping]
\label{def:genomic_mapping}
For nucleotide bases $\{A, T, G, C\}$, the base coordinate mapping function $\psi: \{A,T,G,C\} \rightarrow \mathbb{R}^2$ is:
\begin{align}
\psi(A) &= (0, 1) \quad \text{(North direction)} \\
\psi(T) &= (0, -1) \quad \text{(South direction)} \\
\psi(G) &= (1, 0) \quad \text{(East direction)} \\
\psi(C) &= (-1, 0) \quad \text{(West direction)}
\end{align}
\end{definition}

\begin{remark}
The cardinal direction assignment preserves Watson-Crick base pairing: $A$-$T$ pairs map to opposing vertical directions, while $G$-$C$ pairs map to opposing horizontal directions.
\end{remark}

\begin{definition}[S-Entropy Weighted Coordinate Transformation]
\label{def:sentropy_weighted}
For nucleotide base $b \in \{A,T,G,C\}$ at sequence position $i$ within context window $W_i$, the S-entropy coordinate transformation is:
\begin{equation}
\Phi(b,i,W_i) = (w_k(b,i,W_i) \cdot \psi_x(b), w_t(b,i,W_i) \cdot \psi_y(b), w_e(b,i,W_i) \cdot |\psi(b)|)
\end{equation}
where $w_k$, $w_t$, $w_e$ are knowledge, time, and entropy weighting functions respectively.
\end{definition}

\begin{definition}[Weighting Functions]
\label{def:weighting_functions}
The weighting functions quantify S-entropy components:

\textbf{Knowledge weighting} (information content):
\begin{equation}
w_k(b,i,W_i) = -\sum_{j \in W_i} p_{b_j} \log_2(p_{b_j})
\end{equation}

\textbf{Time weighting} (sequential dynamics):
\begin{equation}
w_t(b,i,W_i) = \frac{\sum_{j=1}^{i} \delta_{b_j,b}}{i}
\end{equation}

\textbf{Entropy weighting} (local disorder):
\begin{equation}
w_e(b,i,W_i) = \sqrt{\sum_{j \in W_i} (\psi(b_j) - \bar{\psi}_{W_i})^2}
\end{equation}
where $p_{b_j}$ is the probability of base $b_j$ in window $W_i$, $\delta_{b_j,b}$ is the Kronecker delta, and $\bar{\psi}_{W_i}$ is the mean coordinate vector in window $W_i$.
\end{definition}

\begin{theorem}[Genomic Path Information Preservation]
\label{thm:genomic_preservation}
The coordinate path $\mathbf{P}(S) = \sum_{i=1}^n \Phi(s_i, i, W_i)$ for genomic sequence $S = s_1s_2...s_n$ preserves all sequence information.
\end{theorem}

\begin{proof}
The coordinate transformation $\Phi$ is injective when considering position and context information. For any two distinct sequences $S_1 \neq S_2$, their coordinate paths satisfy $\mathbf{P}(S_1) \neq \mathbf{P}(S_2)$ because:
\begin{enumerate}
\item Different bases at any position $i$ yield different $\psi(s_i)$ values
\item Context windows $W_i$ incorporate local sequence environment
\item Weighting functions depend on complete local context
\end{enumerate}
Therefore, the mapping is bijective within sequences of identical length and context specifications, ensuring information preservation.
\end{proof}

\subsection{Continuous Emergence}

The discrete ternary structure converges to continuous space in the limit.

\begin{theorem}[Continuous Emergence]
\label{thm:continuous_emergence}
As $k \to \infty$, the discrete $3^k$ cell structure converges to the continuous space $[0,1]^3$:
\begin{equation}
\lim_{k \to \infty} \text{Cell}(t_1,\ldots,t_k) = \Scoord \in [0,1]^3
\end{equation}
\end{theorem}

\begin{proof}
Each trit $t_i$ refines position along one axis by factor $3$. After $k$ refinements, position is determined to precision $3^{-k}$ along each axis. As $k \to \infty$, the precision $3^{-k} \to 0$, and the cell collapses to a point $\Scoord = (\Sk, \St, \Se) \in [0,1]^3$. The mapping is continuous: nearby trit strings (differing in high-index trits) map to nearby points in $[0,1]^3$.
\end{proof}

\begin{corollary}[Coordinate Extraction]
Given infinite trit string $(t_1,t_2,\ldots)$, the S-entropy coordinates are:
\begin{align}
\Sk &= \sum_{i: t_i=0} \frac{c_i^{(k)}}{3^i} \\
\St &= \sum_{i: t_i=1} \frac{c_i^{(t)}}{3^i} \\
\Se &= \sum_{i: t_i=2} \frac{c_i^{(e)}}{3^i}
\end{align}
where $c_i^{(\cdot)} \in \{0,1,2\}$ depends on position within the refined interval.
\end{corollary}

\subsection{Trajectory Encoding}

Ternary strings naturally encode trajectories in S-entropy space.

\begin{theorem}[Trajectory Encoding]
\label{thm:trajectory_encoding}
A trajectory $\gamma: [0,T] \to \Sspace$ with $\gamma(0) = \Scoord_0$ and $\gamma(T) = \Scoord_T$ admits encoding as a ternary string $(t_1,t_2,\ldots,t_k)$ where $t_i$ specifies the direction of motion at step $i$.
\end{theorem}

\begin{proof}
Discretize the trajectory into $k$ steps. At each step, the trajectory moves along one of three axes: $\Sk$, $\St$, or $\Se$. Encode the axis as $t_i \in \{0,1,2\}$. The resulting $k$-trit string uniquely specifies the trajectory up to discretization error $\mathcal{O}(3^{-k})$.
\end{proof}

\begin{corollary}[Trajectory Complexity]
The complexity of a trajectory is quantified by the number of trits required to encode it to precision $\epsilon$:
\begin{equation}
C(\gamma, \epsilon) = \lceil \log_3(1/\epsilon) \rceil
\end{equation}
\end{corollary}

\subsection{Tryte Structure}

A ternary byte (tryte) comprises six trits, encoding $3^6 = 729$ distinct states.

\begin{definition}[Tryte]
A tryte is a $6$-trit ternary string $(t_1,t_2,t_3,t_4,t_5,t_6)$ with $t_i \in \{0,1,2\}$, mapping to a cell in the $729$-partition of $\Sspace$.
\end{definition}

\begin{proposition}[Tryte Capacity]
A $k$-tryte string encodes $729^k$ distinct states, corresponding to $3^{6k}$ cells in S-entropy space.
\end{proposition}

\begin{proof}
Each tryte encodes $6$ trits. A $k$-tryte string contains $6k$ trits, yielding $3^{6k} = 729^k$ distinct states.
\end{proof}

The tryte provides a natural unit for cellular information processing, with $729$ states sufficient to encode typical molecular configurations at physiological resolution.

\subsection{Arithmetic Operations}

Ternary arithmetic admits efficient implementation of S-entropy coordinate operations.

\begin{definition}[Ternary Addition]
Addition of two trits $t_1, t_2 \in \{0,1,2\}$ produces sum $s$ and carry $c$:
\begin{align}
s &= (t_1 + t_2) \mod 3 \\
c &= \lfloor (t_1 + t_2) / 3 \rfloor
\end{align}
\end{definition}

\begin{proposition}[Coordinate Addition]
Addition of two S-entropy coordinates $\Scoord_1$ and $\Scoord_2$ encoded as ternary strings proceeds trit-wise with carry propagation.
\end{proposition}

\begin{proof}
Represent $\Scoord_1 = (t_1^{(1)}, t_2^{(1)}, \ldots)$ and $\Scoord_2 = (t_1^{(2)}, t_2^{(2)}, \ldots)$. Compute $s_i = (t_i^{(1)} + t_i^{(2)} + c_{i-1}) \mod 3$ and $c_i = \lfloor (t_i^{(1)} + t_i^{(2)} + c_{i-1}) / 3 \rfloor$ for $i = 1, 2, \ldots$ with $c_0 = 0$. The result is $\Scoord_1 + \Scoord_2 = (s_1, s_2, \ldots)$.
\end{proof}

\subsection{Distance Metrics}

Ternary encoding enables efficient distance computation in S-entropy space.

\begin{definition}[Hamming Distance]
The Hamming distance between two $k$-trit strings $(t_1,\ldots,t_k)$ and $(t_1',\ldots,t_k')$ is:
\begin{equation}
d_H = \sum_{i=1}^{k} \mathbb{1}_{t_i \neq t_i'}
\end{equation}
\end{definition}

\begin{proposition}[Hamming-Euclidean Relation]
For $k$-trit encodings of S-entropy coordinates $\Scoord_1$ and $\Scoord_2$, the Hamming distance provides an upper bound on Euclidean distance:
\begin{equation}
\|\Scoord_1 - \Scoord_2\| \leq \sqrt{3} \cdot d_H \cdot 3^{-k}
\end{equation}
\end{proposition}

\begin{proof}
Each differing trit contributes at most $3^{-k}$ to coordinate difference along one axis. The maximum Euclidean distance from $d_H$ differing trits is $\sqrt{d_H} \cdot 3^{-k}$ if differences are distributed across axes, or $d_H \cdot 3^{-k}$ if concentrated on one axis. The worst case is $\sqrt{3} \cdot d_H \cdot 3^{-k}$ for uniform distribution across three axes.
\end{proof}

\subsection{Hardware Implementation}

Ternary encoding admits natural hardware implementation through three-phase oscillators.

\begin{proposition}[Three-Phase Oscillator]
A three-phase oscillator with phases $\phi_0 = 0$, $\phi_1 = 2\pi/3$, $\phi_2 = 4\pi/3$ naturally encodes trits through phase detection.
\end{proposition}

\begin{proof}
Measure oscillator phase $\phi(t)$ at time $t$. Assign trit value:
\begin{equation}
t = \begin{cases}
0 & \text{if } |\phi(t) - \phi_0| < \pi/3 \\
1 & \text{if } |\phi(t) - \phi_1| < \pi/3 \\
2 & \text{if } |\phi(t) - \phi_2| < \pi/3
\end{cases}
\end{equation}
The three phases partition the oscillation cycle into three equal regions, providing robust trit encoding.
\end{proof}

\begin{corollary}[Molecular Oscillator]
Molecular oxygen with three accessible spin states ($S = 0, 1, 2$ for singlet, triplet, quintet) provides natural ternary encoding substrate.
\end{corollary}

The oxygen triplet ground state, singlet excited state, and quintet excited state correspond to $t = 1$, $t = 0$, and $t = 2$ respectively, enabling direct molecular implementation of ternary encoding \citep{herzberg1950molecular}.

\subsection{Information Density}

Ternary encoding achieves higher information density than binary encoding.

\begin{proposition}[Ternary-Binary Efficiency]
Ternary encoding achieves $\log_2(3) \approx 1.585$ bits per trit, compared to $1$ bit per binary digit.
\end{proposition}

\begin{proof}
A $k$-trit string encodes $3^k$ distinct states. The equivalent binary string requires $\lceil k \log_2(3) \rceil$ bits. The ratio is $\log_2(3)/1 \approx 1.585$.
\end{proof}

\begin{corollary}[Storage Efficiency]
For fixed physical volume, ternary encoding provides $58.5\%$ more information storage than binary encoding.
\end{corollary}

This efficiency advantage motivates ternary encoding for cellular information processing, where physical volume is constrained \citep{hayes2001ternary}.

\subsection{Cellular Implementation}

Cellular systems implement ternary encoding through molecular state multiplexing.

\begin{proposition}[Molecular Ternary Encoding]
A molecule with three distinguishable states (e.g., three conformations, three charge states, three spin states) encodes one trit.
\end{proposition}

\begin{proof}
Categorical observation distinguishes three molecular states. Map states to trit values $\{0,1,2\}$. The molecule functions as a ternary memory element.
\end{proof}

Oxygen molecules with triplet ground state, singlet excited state, and quintet excited state provide natural ternary encoding. Hemoglobin with four oxygen binding sites provides $3^4 = 81$ distinct states, encoding $\log_2(81) \approx 6.34$ bits per molecule \citep{perutz1970stereochemistry}.

