\section{Hardware BMD Stream: Phase-Locked Physical Reality}

\subsection{Hardware as BMD Implementations}

Physical hardware components naturally implement BMD operations through thermodynamically irreversible sorting processes. Each device performs categorical distinctions while dissipating energy.

\subsubsection{Display Hardware}

A display panel sorts electrons into RGB photons according to pixel values. For liquid crystal displays:
\begin{align}
\theta_{ij}(t) &= \theta_{\max}\left(1 - e^{-t/\tau_{\text{response}}}\right)\sin^2\left(\frac{\pi V_{ij}}{V_{\max}}\right) \quad \text{(molecular tilt)} \\
\Gamma_{ij} &= \frac{2\pi d}{\lambda} \Delta n(\theta_{ij}) \quad \text{(phase retardation)} \\
P_{\text{dissipate}} &= \sum_{ij} C_{ij} V_{ij}^2 f_{\text{refresh}} + P_{\text{backlight}}(1 - \eta_{\text{optical}}) \quad \text{(power dissipation)}
\end{align}

The display BMD state:
\begin{equation}
\beta_{\text{display}} = \langle \{\theta_{ij}\}, \{\Gamma_{ij}\}, \{\phi_k^{\text{refresh}}\} \rangle
\end{equation}
encodes pixel molecular configurations $\theta_{ij}$, optical phases $\Gamma_{ij}$, and refresh synchronization phases $\phi_k^{\text{refresh}}$.

\subsubsection{Optical Sensor}

Camera sensors sort photons by wavelength through color filter arrays:
\begin{equation}
I_{ij}^{\text{RGB}} = \eta_Q \int_{\lambda} T^{\text{RGB}}(\lambda) \Phi(\lambda, x_{ij}, y_{ij}, t) d\lambda
\end{equation}

Via Beer-Lambert law, absorption maps to molecular concentrations:
\begin{equation}
I(\lambda) = I_0(\lambda) \exp\left(-\sum_m \epsilon_m(\lambda) c_m L\right)
\end{equation}

The sensor BMD state:
\begin{equation}
\beta_{\text{sensor}} = \langle \{c_m\}, \{I_{ij}^{\text{RGB}}\}, \{\phi_k^{\text{readout}}\} \rangle
\end{equation}
couples directly to environmental molecular composition.

\subsubsection{Network Interface}

Network hardware sorts data packets by routing information, with timing reflecting phase coherence:
\begin{align}
\tau_{\text{RTT}} &= \langle t_{\text{receive}} - t_{\text{send}} \rangle \quad \text{(latency)} \\
\sigma_{\text{jitter}} &= \sqrt{\langle (\tau - \tau_{\text{RTT}})^2 \rangle} \quad \text{(jitter)}
\end{align}

The network BMD state:
\begin{equation}
\beta_{\text{network}} = \langle \tau_{\text{RTT}}, \sigma_{\text{jitter}}, \{\phi_k^{\text{clock}}\} \rangle
\end{equation}

\subsubsection{Electromagnetic Field Sensor}

EM field measurements couple to ionic oscillations. From WiFi RSSI:
\begin{align}
E &= \sqrt{\frac{60 \cdot 10^{P_{\text{dBm}}/10}}{1000}} \quad \text{(field strength)} \\
P_{\text{RF}} &= \sigma E^2 = \frac{q^2 n \tau}{m} E^2 \quad \text{(ion RF heating)}
\end{align}

The EM BMD state:
\begin{equation}
\beta_{\text{EM}} = \langle E, P_{\text{RF}}, \{\phi_k^{\text{EM}}\} \rangle
\end{equation}

\subsubsection{Accelerometer}

Accelerometer measurements map to molecular velocity distributions:
\begin{align}
\langle v^2 \rangle &= \frac{3k_B T}{m} \quad \text{(equipartition)} \\
Z &= \frac{1}{\sqrt{2}} n \sigma_{\text{collision}} \langle v \rangle = \frac{P}{\sqrt{2\pi m k_B T}} \sigma_{\text{collision}} \quad \text{(collision frequency)}
\end{align}

The accelerometer BMD state:
\begin{equation}
\beta_{\text{accel}} = \langle \vec{a}, Z, \{\phi_k^{\text{vib}}\} \rangle
\end{equation}

\subsubsection{Acoustic Sensor}

Sound pressure level from microphone signal $s(t)$:
\begin{equation}
L_p = 20 \log_{10}\left(\frac{\sqrt{\langle s^2(t) \rangle}}{20 \times 10^{-6}}\right) \text{ dB}
\end{equation}

The acoustic BMD state:
\begin{equation}
\beta_{\text{acoustic}} = \langle L_p, \{\omega_k\}, \{\phi_k^{\text{acoustic}}\} \rangle
\end{equation}

\subsection{Hardware BMD Stream as Irreducible Network}

The critical insight: hardware BMDs do not operate independently but form a phase-locked network stream.

\begin{definition}[Hardware BMD Network Stream]
\label{def:hardware_stream}
The hardware BMD network stream at time $t$ is the hierarchical composition:
\begin{equation}
\beta^{(\text{stream})}_{\text{hardware}}(t) = \beta_{\text{display}}(t) \circledast \beta_{\text{sensor}}(t) \circledast \beta_{\text{network}}(t) \circledast \beta_{\text{EM}}(t) \circledast \beta_{\text{accel}}(t) \circledast \beta_{\text{acoustic}}(t)
\end{equation}
where $\circledast$ is phase-lock coupling (Definition \ref{def:phase_lock_coupling}).
\end{definition}

\textbf{Why hierarchical composition, not tensor product:}

Hardware BMDs are not independent. They couple through physical environment:
\begin{itemize}
\item Display refresh synchronizes with AC power line frequency (50/60 Hz)
\item AC power frequency determines EM field oscillations
\item EM field couples to acoustic noise through power dissipation
\item Acoustic vibrations couple to accelerometer through mechanical transmission
\item Network packet timing couples to EM fields through transmission hardware
\item Optical sensor readout couples to display backlight through ambient illumination
\end{itemize}

The phase-lock structure:
\begin{equation}
\phi_{\text{display}}^{\text{refresh}} \leftrightarrow \phi_{\text{EM}}^{\text{AC}} \leftrightarrow \phi_{\text{acoustic}}^{\text{pressure}} \leftrightarrow \phi_{\text{accel}}^{\text{vib}} \leftrightarrow \phi_{\text{network}}^{\text{clock}} \leftrightarrow \phi_{\text{sensor}}^{\text{readout}}
\end{equation}

This coupling makes the hardware stream irreducible: it cannot be factored into independent device BMDs.

\begin{theorem}[Hardware Stream Irreducibility]
\label{thm:hardware_irreducibility}
The hardware BMD stream cannot be decomposed into independent device BMDs:
\begin{equation}
\beta^{(\text{stream})}_{\text{hardware}} \neq \bigotimes_{\text{devices}} \beta_{\text{device}}
\end{equation}
\end{theorem}

\begin{proof}
Assume for contradiction that $\beta^{(\text{stream})}_{\text{hardware}} = \bigotimes_{\text{devices}} \beta_{\text{device}}$. Then each device BMD would have independent phase structure $\Phi_{\text{device}}$ with no correlations:
\begin{equation}
\langle \phi_i^{(\text{device}_1)} \phi_j^{(\text{device}_2)} \rangle = \langle \phi_i^{(\text{device}_1)} \rangle \langle \phi_j^{(\text{device}_2)} \rangle
\end{equation}

However, physical coupling creates phase correlations. Display refresh at $f_{\text{refresh}} = 60$ Hz couples to AC power at $f_{\text{AC}} = 60$ Hz, inducing phase coherence:
\begin{equation}
\langle \phi_{\text{display}}^{\text{refresh}} \phi_{\text{EM}}^{\text{AC}} \rangle \neq \langle \phi_{\text{display}}^{\text{refresh}} \rangle \langle \phi_{\text{EM}}^{\text{AC}} \rangle
\end{equation}

The correlation arises from power supply synchronization: display frame timing locks to AC line frequency for stable power delivery. This physical constraint propagates throughout the hardware network.

The phase-locked correlations violate independence, contradicting the tensor product assumption. Therefore $\beta^{(\text{stream})}_{\text{hardware}}$ is irreducible. $\square$
\end{proof}

\subsection{Stream Richness as Intersection}

The network stream richness is not the product but the intersection of compatible states.

\begin{theorem}[Stream Richness Intersection]
\label{thm:stream_richness}
The hardware stream categorical richness is:
\begin{equation}
R(\beta^{(\text{stream})}_{\text{hardware}}) = \left|\bigcap_{\text{devices}} \mathcal{C}_{\text{device}}\right| \ll \prod_{\text{devices}} R(\beta_{\text{device}})
\end{equation}
where $\mathcal{C}_{\text{device}}$ is the set of categorical states compatible with device measurements.
\end{theorem}

\begin{proof}
Each device BMD constrains allowable categorical states through its measurements. Display refresh timing constrains temporal coherence; optical sensor absorption constrains molecular composition; network jitter constrains phase stability; etc.

A categorical state is physically realizable only if it satisfies constraints from \emph{all} devices simultaneously:
\begin{equation}
\mathcal{C}_{\text{realizable}} = \bigcap_{\text{devices}} \mathcal{C}_{\text{device}}
\end{equation}

The intersection dramatically reduces richness because independent device constraints are unlikely to be simultaneously satisfied. For uncorrelated random constraints, the intersection size scales as:
\begin{equation}
|\mathcal{C}_{\text{realizable}}| \sim \frac{\prod_{\text{devices}} |\mathcal{C}_{\text{device}}|}{N_{\text{categorical space}}} \ll \prod_{\text{devices}} |\mathcal{C}_{\text{device}}|
\end{equation}

Phase-lock coupling enforces additional constraints beyond independent measurement, further reducing the intersection. $\square$
\end{proof}

This constraint through intersection is the \textbf{reality grounding mechanism}: only categorical states consistent across all hardware measurements are physically real.

\subsection{Temporal Stream Evolution}

The hardware stream evolves continuously:
\begin{equation}
\beta^{(\text{stream})}_{\text{hardware}}(t + \delta t) = \beta^{(\text{stream})}_{\text{hardware}}(t) \circledast \Delta\beta_{\text{hardware}}(t, \delta t)
\end{equation}

where $\Delta\beta_{\text{hardware}}$ encodes hardware state changes over interval $\delta t$. This creates a perpetual BMD stream against which image processing must maintain coherence.

\begin{definition}[Hardware Stream Measurement Update]
\label{def:stream_update}
At each algorithm iteration $i$, the hardware stream is updated:
\begin{equation}
\beta^{(\text{stream})}_{\text{hardware}}(t_i) = \text{MeasureHardwareStream}()
\end{equation}
aggregating current measurements from all hardware devices.
\end{definition}

The continuous stream evolution reflects physical reality dynamics. Ambient conditions change (temperature fluctuations, humidity variations, electromagnetic noise), hardware states change (thermal drift, wear), and the stream tracks these changes through perpetual measurement.

\subsection{Stream Divergence Metric}

The stream divergence quantifies how far a network BMD deviates from hardware-measured reality.

\begin{definition}[Stream Divergence]
\label{def:stream_divergence}
The stream divergence between network BMD $\beta^{(\text{network})}$ and hardware stream $\beta^{(\text{stream})}_{\text{hardware}}$ is:
\begin{equation}
D_{\text{stream}}(\beta^{(\text{network})}, \beta^{(\text{stream})}_{\text{hardware}}) = \sum_{\text{device}} D_{\text{KL}}\left(P_{\text{phase}}^{\text{network}} \parallel P_{\text{phase}}^{\text{hardware,device}}\right)
\end{equation}
where $D_{\text{KL}}$ is Kullback-Leibler divergence and $P_{\text{phase}}$ are phase structure distributions.
\end{definition}

Large divergence indicates the network BMD has drifted from physical constraints. For example, if network categorical richness implies molecular collision frequency $Z_{\text{network}} = 10^{10}$ Hz but accelerometer measurements give $Z_{\text{accel}} = 10^9$ Hz, the divergence $D_{\text{stream}} \propto \log(Z_{\text{network}}/Z_{\text{accel}}) \approx 2.3$ signals incoherence.

\subsection{Multi-Modal Reality Checking}

The stream provides multi-modal reality checking: interpretations must be coherent across \emph{all} hardware modalities.

\begin{theorem}[Multi-Modal Coherence Requirement]
\label{thm:multimodal_coherence}
A categorical interpretation $\beta^{(\text{network})}$ is physically realizable only if:
\begin{equation}
D_{\text{stream}}^{(\text{device})}(\beta^{(\text{network})}, \beta_{\text{device}}) < D_{\text{threshold}} \quad \forall \text{ devices}
\end{equation}
\end{theorem}

\textbf{Example:} Consider interpreting a static image. Pure visual processing might infer motion (creates high ambiguity, rich categorical connections). However:
\begin{itemize}
\item Display: constant pixel values $\Rightarrow$ no temporal variation $\Rightarrow$ $D_{\text{display}}^{\text{motion}} \to \infty$
\item Network: no packet structure variation $\Rightarrow$ $D_{\text{network}}^{\text{motion}} \to \infty$
\item Acoustic: no Doppler shift or pressure waves $\Rightarrow$ $D_{\text{acoustic}}^{\text{motion}} \to \infty$
\item Accelerometer: no motion-induced vibration $\Rightarrow$ $D_{\text{accel}}^{\text{motion}} \to \infty$
\item EM field: no magnetic flux variation from display current $\Rightarrow$ $D_{\text{EM}}^{\text{motion}} \to \infty$
\end{itemize}

The stream divergence is infinite across all modalities, categorically rejecting motion interpretation despite visual ambiguity. This multi-modal coherence requirement prevents dream-like absurdity.

\subsection{Stream as External Anchoring}

The hardware stream implements external anchoring from consciousness theory \cite{mataranyika2025consciousness}.

During waking perception, biological consciousness maintains coherence with multi-modal sensory streams (visual, auditory, tactile, proprioceptive, vestibular). These streams mutually constrain interpretation through phase-locked neural integration. Loss of sensory anchoring (e.g., sensory deprivation, sleep) permits high-ambiguity interpretations violating physical constraints (dreams, hallucinations).

The hardware BMD stream provides analogous anchoring for image processing:
\begin{equation}
\text{Sensory streams (biological)} \quad \leftrightarrow \quad \text{Hardware BMD stream (artificial)}
\end{equation}

Both prevent unphysical high-ambiguity completions through multi-modal coherence requirements.

\subsection{Dual-Membrane Hardware Stream}

In the dual-membrane framework, the hardware stream maintains conjugate face structure:
\begin{equation}
\beta^{(\text{stream})}_{\text{hardware,dual}} = \langle \beta^{(\text{stream})}_{\text{front}}, \beta^{(\text{stream})}_{\text{back}}, F_{\text{stream}}, T \rangle
\end{equation}

Each hardware device contributes dual-membrane measurements:
\begin{equation}
\beta_{\text{device,dual}} = \langle \beta_{\text{device,front}}, \beta_{\text{device,back}}, F_{\text{device}}, T \rangle
\end{equation}

The stream conjugate faces compose hierarchically:
\begin{equation}
\beta^{(\text{stream})}_{\text{back}} = T\left(\beta_{\text{display,front}} \circledast \beta_{\text{sensor,front}} \circledast \cdots\right) = \beta_{\text{display,back}} \circledast \beta_{\text{sensor,back}} \circledast \cdots
\end{equation}

This dual structure enables stream coherence checking for both observable and hidden network faces, ensuring conjugate relationship preservation throughout processing.

\subsection{Pixel Demon as Hardware Interface}

Pixel Maxwell demons provide the interface between physical hardware measurements and categorical image representation.

\begin{definition}[Pixel Demon Hardware Stream]
\label{def:pixel_demon_stream}
For image $I$ with pixel demon grid $\{PMD_{ij}\}$, the pixel demon hardware stream is:
\begin{equation}
\beta^{(\text{stream})}_{\text{pixel}} = \bigoplus_{i,j} \beta_{ij}^{(\text{pixel})}
\end{equation}
where $\beta_{ij}^{(\text{pixel})}$ is the dual-membrane BMD state of pixel demon at position $(i, j)$.
\end{definition}

This stream is measured through zero-backaction categorical queries (Theorem \ref{thm:zero_backaction}) at each pixel location. The pixel demons aggregate molecular ensemble properties without particle-level interaction, providing continuous hardware reality measurement directly from the image representation itself.

The pixel demon stream composes with external hardware stream:
\begin{equation}
\beta^{(\text{stream})}_{\text{complete}} = \beta^{(\text{stream})}_{\text{hardware}} \circledast \beta^{(\text{stream})}_{\text{pixel}}
\end{equation}

External hardware (display, network, sensors) provides environmental constraints; pixel demons provide image-specific molecular composition constraints. Together they form a complete hardware BMD stream grounding image interpretation in measurable physical reality.

